{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f214f833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                     authorId  commentCount             dateTime  \\\n",
      "0              habloconpabl0         25100  2022-03-27 21:56:15   \n",
      "1            alitravelsbroke          7107  2022-12-11 16:01:09   \n",
      "2               kristinacors         11700  2020-06-10 00:13:34   \n",
      "3                dashakofman          3326  2022-08-22 23:36:57   \n",
      "4                  paniluiza          3677  2022-12-31 15:21:43   \n",
      "...                      ...           ...                  ...   \n",
      "10594             sedyyfilms         11300  2025-02-22 01:16:32   \n",
      "10595        swiss_beautiful         35200  2024-03-31 15:03:19   \n",
      "10596              yessipcas           596  2024-09-05 14:54:32   \n",
      "10597  cristynguyen.official           194  2023-07-15 14:51:34   \n",
      "10598                fayesxh           136  2025-03-31 17:41:23   \n",
      "\n",
      "                                                    desc  diggCount  \\\n",
      "0      Chueca es genial ðŸ˜­ #madridgay #madridgaylife #...    2600000   \n",
      "1      Driving in morocco & seeing a tree full of goa...    1300000   \n",
      "2      This country will basically PAY tourists to vi...    1300000   \n",
      "3      secret spots in london, pt. one #londontravelg...    1000000   \n",
      "4      I found travel gem in Germany, second Venice i...     788300   \n",
      "...                                                  ...        ...   \n",
      "10594  pov: you take an evening walk in nyc #cinemati...    2600000   \n",
      "10595  Isn't Switzerland beautiful?ðŸ‡¨ðŸ‡­#switzerland #sw...    8200000   \n",
      "10596  Mi querida Francia â™¥ï¸ðŸ‡«ðŸ‡·!. AquÃ­ es ANNECY  #fyp...      44700   \n",
      "10597  Muá»‘n giÃ nh cáº£ ngÃ y Ä‘á»ƒ á»Ÿ Ä‘Ã¢y luÃ´n ðŸ’“ #cristynguy...      28500   \n",
      "10598  Only a girl solo travelling around the world â¤...      10900   \n",
      "\n",
      "       duetEnabled  duetFromId  \\\n",
      "0            False           0   \n",
      "1             True           0   \n",
      "2             True           0   \n",
      "3             True           0   \n",
      "4             True           0   \n",
      "...            ...         ...   \n",
      "10594         True           0   \n",
      "10595         True           0   \n",
      "10596        False           0   \n",
      "10597         True           0   \n",
      "10598         True           0   \n",
      "\n",
      "                                            hashtagNames  \\\n",
      "0      madridgay, madridgaylife, gaymadridsoltero, di...   \n",
      "1      traveltiktok, solotravel, backpacking, solofem...   \n",
      "2      travel, traveladvice, traveltips, travelbucket...   \n",
      "3      londontravelguide, londontravel, londonlife, l...   \n",
      "4      2023summer, 2023traveltrends, 2023travelgoals,...   \n",
      "...                                                  ...   \n",
      "10594  cinematic, cinematography, videography, filmma...   \n",
      "10595  switzerland, swissroads, switzerlandnature, ro...   \n",
      "10596  fyp, parati, foryou, france, travel, viajes, v...   \n",
      "10597  cristynguyen, dulich, dulichonline, dulichtikt...   \n",
      "10598  foryou, thailand, travel, girl, foryou, thaila...   \n",
      "\n",
      "                                            stickersText  \\\n",
      "0      I forgot they were in my pocket and now the do...   \n",
      "1      pov youâ€™re driving in morocco & see a tree ful...   \n",
      "2      Destinations that will practically PAY YOU to ...   \n",
      "3         secret spots in london \\npt. one, ðŸ“Neals Yard    \n",
      "4      Itâ€™s just a small village \\nin Germany, whatâ€™s...   \n",
      "...                                                  ...   \n",
      "10594                                                NaN   \n",
      "10595                       SwitzerlandðŸ‡¨ðŸ‡­, SwitzerlandðŸ‡¨ðŸ‡­   \n",
      "10596                         FRANCIA\\nðŸ‡«ðŸ‡·Â , FRANCIA\\nðŸ‡«ðŸ‡·Â    \n",
      "10597                                                NaN   \n",
      "10598                                                NaN   \n",
      "\n",
      "                             musicAlbum   musicAuthorName       musicId  \\\n",
      "0      Melody of Certain Damaged Lemons    Blonde Redhead  6.793807e+18   \n",
      "1                                   NaN        traduction  7.155074e+18   \n",
      "2                 Roses (Imanbek Remix)         SAINt JHN  6.754297e+18   \n",
      "3                                   NaN       xxtristanxo  7.131108e+18   \n",
      "4                                   NaN    uiitraviolence  7.157013e+18   \n",
      "...                                 ...               ...           ...   \n",
      "10594                               NaN        SedyyFilms  7.474046e+18   \n",
      "10595                               NaN  TrendformusicðŸ¤ðŸ‡²ðŸ‡º  7.036003e+18   \n",
      "10596                  Beautiful Things      Benson Boone  7.308548e+18   \n",
      "10597                               NaN             My Le  7.256043e+18   \n",
      "10598                               NaN   lana del rey à­¨à­§  7.445702e+18   \n",
      "\n",
      "                       musicTitle  playCount  shareCount              videoId  \\\n",
      "0            For the Damaged Coda   27200000       41800  7079886686729260334   \n",
      "1                    son original    6400000       15200  7175921679036714245   \n",
      "2           Roses (Imanbek Remix)    7800000      233800  6836490196624624902   \n",
      "3                  original sound    6000000       13600  7134833226027158830   \n",
      "4      west coast apollo353 remix    5800000       22400  7183333223236177179   \n",
      "...                           ...        ...         ...                  ...   \n",
      "10594              original sound   14100000      233200  7474046175163780374   \n",
      "10595                son original   74300000      266000  7352527854741015840   \n",
      "10596            Beautiful Things     674100        2730  7411157053219048709   \n",
      "10597                    nháº¡c ná»n     597200         699  7256042602598796586   \n",
      "10598  cinnamon girl lana del rey     135400         673  7488014691592047894   \n",
      "\n",
      "                                               videoLink  \n",
      "0      https://www.tiktok.com/@6755279996182348805/vi...  \n",
      "1      https://www.tiktok.com/@7008216250564805637/vi...  \n",
      "2      https://www.tiktok.com/@6747770185614312453/vi...  \n",
      "3      https://www.tiktok.com/@6764845416200307717/vi...  \n",
      "4      https://www.tiktok.com/@7175147257800639494/vi...  \n",
      "...                                                  ...  \n",
      "10594  https://www.tiktok.com/@7315534246582780960/vi...  \n",
      "10595  https://www.tiktok.com/@6982951063335044102/vi...  \n",
      "10596  https://www.tiktok.com/@6776278529107641349/vi...  \n",
      "10597  https://www.tiktok.com/@15702247/video/7256042...  \n",
      "10598  https://www.tiktok.com/@53039534656983040/vide...  \n",
      "\n",
      "[10599 rows x 17 columns]>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('../csv/unique_videos_df.csv')\n",
    "print (dataset.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56216c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10599"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf36b42",
   "metadata": {},
   "source": [
    "#First phase of coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee126375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONAR_KEY loaded successfully.\n",
      "Found existing results file: 'analysis_results.json'. Resuming...\n",
      "Loaded 10587 previously processed videos.\n",
      "\n",
      "--- Starting analysis on 12 remaining videos ---\n",
      "Processing 1/12 - Video ID: 7326756230951619846\n",
      "Processing 2/12 - Video ID: 7422738311665421586\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with codes and reasons. But wait, the input data isn't actually provided here. The user mentioned \"Content Description,\" \"Hashtags,\" and \"Captions,\" but those fields are empty. Hmm, that's a problem. Without the actual content, I can't apply the codes properly.\n",
      "\n",
      "First, I need to check if I missed something. The search results include information about JSON structures, which might be relevant for formatting the output. The codebook has various categories like Journey Narratives, Digital Representation, etc. Each code has a label and description. The task is to assign up to five codes based on the content.\n",
      "\n",
      "But since there's no content provided, I can't determine which codes apply. The user might have intended to include example data but forgot. Without that, I can't proceed accurately. Maybe they want a template or an example of how the JSON should look? Let me look at the instructions again.\n",
      "\n",
      "The instructions say to return a JSON object wrapped in <json_output> tags. The example in the search results shows JSON structures with objects and arrays. The codebook's codes need to be mapped to the content. But without content, I can't justify any codes. \n",
      "\n",
      "Wait, maybe the user expects a placeholder response? But the instructions are strict: only a JSON object with codes and reasons. Since there's no data, I can't generate valid codes. The correct approach here is to inform the user that the input data is missing and the analysis can't be performed. However, the user specified to provide the response only as a JSON object. \n",
      "\n",
      "But how to handle this? The instructions say to provide the response only as a JSON object. If there's no data, maybe return an empty JSON object? But that's not helpful. Alternatively, perhaps the user made a mistake in not providing the data. In that case, the assistant should point out the missing information. However, the instructions say to avoid explanations outside the JSON tags. \n",
      "\n",
      "This is a dilemma. The user's query is incomplete, but they want a JSON response. The correct action is to inform them that the input data is missing. But according to the instructions, the response must be a JSON object. Maybe the assistant should return a JSON object indicating that the data is missing. For example:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data (Content Description, Hashtags, Captions) is missing. Analysis cannot be performed.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But the instructions say to provide codes and reasons based on the data. Since there's no data, the codes array is empty, and the reason explains why. This adheres to the structure required. The search results about JSON structures support this approach, as an empty object is valid. \n",
      "\n",
      "Alternatively, maybe the user intended to include example data but forgot. In that case, the assistant should ask for clarification. But the instructions don't allow for that; the response must be a JSON object. \n",
      "\n",
      "Given all this, the appropriate response is to return a JSON object with empty codes and a reason stating the missing data. This follows the user's instructions strictly while addressing the lack of input.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data (Content Description, Hashtags, Captions) is missing. Analysis cannot be performed without content to evaluate against the codebook criteria.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7422738311665421586 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 3/12 - Video ID: 7354051976902020385\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with codes and reasons. But wait, the input data isn't actually provided here. The user mentioned \"Input Data\" with placeholders for Content Description, Hashtags, and Captions, but there's no real data to work with. Hmm, that's a problem.\n",
      "\n",
      "First, I need to check if I missed something. Let me look through the search results again. The search results include information about JSON structures, some GitHub issues, a JSON object structure example, a Hugging Face dataset example, and a partial link that's cut off. None of these seem to contain the actual TikTok data the user is referring to. The user's query is about analyzing data that's supposed to be provided, but it's not here.\n",
      "\n",
      "So, the main issue is that the necessary input data isn't present in the search results. Without the Content Description, Hashtags, and Captions, I can't apply the codebook to determine the relevant codes. The codebook has various categories like Journey Narratives, Digital Representation, etc., each with specific codes. But without the actual content, I can't match any of these codes.\n",
      "\n",
      "The user's instructions are strict: they want only a JSON object wrapped in <json_output> tags, nothing else. But since there's no data to analyze, I can't generate a valid JSON response. I need to inform the user that the input data is missing. However, the user's instructions say to provide the response only as a JSON object. But how can I do that without data?\n",
      "\n",
      "Wait, maybe the user made a mistake in providing the input data. The \"Input Data\" section has placeholders but no actual content. The search results don't include any TikTok data either. So, the correct approach here is to point out that the input data is missing and therefore an analysis can't be performed. But according to the instructions, I should only output a JSON object. This is a conflict.\n",
      "\n",
      "Alternatively, perhaps the user intended to include the input data but forgot. In that case, I should respond by stating that the input data is missing and ask for it. But again, the instructions say to provide only a JSON object. This is a bit of a dilemma.\n",
      "\n",
      "Looking at the codebook, the codes require specific elements in the content. For example, JN-TE (Transformative Experiences) would need mentions of self-actualization through travel. Without any content, I can't assign any codes. The same applies to all other codes. Therefore, the correct response is to inform the user that the input data is missing, but since the instructions require a JSON object, maybe return an empty JSON or a placeholder.\n",
      "\n",
      "But the user's example in the instructions shows a JSON with codes and reasons. If there's no data, perhaps the JSON should have empty arrays or null values. However, the instructions say to provide a valid JSON object. An empty JSON might not be valid in this context. Alternatively, maybe return a JSON with a message indicating missing data.\n",
      "\n",
      "But the user's instructions are very strict: \"Your final output MUST be ONLY a valid JSON object enclosed within <json_output> tags.\" So, I can't include any text outside those tags. Therefore, the only possible response is to return an empty JSON object or a JSON with a message. However, the codebook requires codes and reasons. Without data, I can't generate those.\n",
      "\n",
      "In conclusion, the correct approach is to inform the user that the input data is missing, but since the instructions require a JSON object, perhaps return a JSON with a message. However, the user's example in the instructions shows a JSON with codes and reasons. Since there's no data, maybe return a JSON with an empty codes array and a reason stating that the input data is missing.\n",
      "\n",
      "But the user's instructions say to \"provide your response ONLY as a JSON object wrapped in <json_output> tags.\" So, the answer must be a JSON object, even if it's empty. Therefore, the response would be:\n",
      "\n",
      "<json_output>{}</json_output>\n",
      "\n",
      "But that's an empty JSON object. Alternatively, maybe include a message in the JSON. For example:\n",
      "\n",
      "<json_output>{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data is missing.\"\n",
      "}</json_output>\n",
      "\n",
      "But the user's codebook requires up to 5 codes and a reason. Since there's no data, the codes array is empty, and the reason explains why. This seems appropriate. However, the user's instructions don't mention handling missing data, so this is an assumption. But given the constraints, this is the best possible response.\n",
      "</think>\n",
      "\n",
      "<json_output>{}</json_output>\n",
      "    *** FAILED to process Video ID: 7354051976902020385 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 4/12 - Video ID: 7345270896703130923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with specific codes and reasons. But wait, the input data they provided is emptyâ€”Content Description, Hashtags, and Captions are all blank. Hmm, that's a problem. Without any actual data to analyze, how can I apply the codes from the codebook?\n",
      "\n",
      "First, I need to check if I'm missing something. The user mentioned \"Input Data\" but didn't include any content. Maybe it's a mistake, or perhaps the data was supposed to be in the search results? Let me look through the search results again to see if there's any relevant data I can use.\n",
      "\n",
      "Looking at the search results, result [4] has some JSON examples from a Hugging Face dataset. There's a system message about a JavaScript console and some user interactions. But that's about coding, not TikTok content. The other results are about JSON structures, GitHub issues, and JSON schema examples. None of these relate to TikTok data analysis or the codebook provided.\n",
      "\n",
      "Since the input data is missing, I can't perform the analysis as instructed. The codebook requires specific elements like Content Description, Hashtags, and Captions to assign codes. Without these, I can't determine which codes apply. For example, if the content was about a transformative travel experience, I might use JN-TE. But without any data, I can't make that judgment.\n",
      "\n",
      "The user also emphasized that the response must be a JSON object wrapped in <json_output> tags. But since there's no data to analyze, creating such a JSON would be incorrect. It would either be empty or contain invalid codes without justification.\n",
      "\n",
      "I should inform the user that the input data is missing and that I can't proceed with the analysis. However, the instructions say to provide a JSON object regardless. Maybe the user expects a placeholder or an example? But according to the instructions, I must follow the codebook strictly. Without data, I can't assign any codes accurately.\n",
      "\n",
      "Alternatively, maybe the user intended to include data in the query but forgot. In that case, I should ask for clarification. But since I can't interact, I have to state that the input data is missing and thus the analysis can't be performed.\n",
      "\n",
      "In conclusion, the correct approach is to point out the missing data and explain that without it, the analysis can't be completed. The JSON output would be invalid or empty, which isn't helpful. Therefore, the appropriate response is to inform the user of the missing information and request the necessary data to proceed.\n",
      "</think>\n",
      "\n",
      "<json_output>{}</json_output>\n",
      "    *** FAILED to process Video ID: 7345270896703130923 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 5/12 - Video ID: 7351440334913604870\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with codes and reasons. But wait, the input data isn't actually provided here. The user mentioned \"Content Description,\" \"Hashtags,\" and \"Captions\" but left them empty. Hmm, that's a problem. Without the actual data, I can't apply the codebook to determine relevant codes.\n",
      "\n",
      "Looking at the search results, maybe there's something there. The first result talks about JSON structures, which is relevant since the output needs to be a JSON object. The second result has some GitHub issues, but not helpful here. The third result explains JSON objects with key-value pairs, which aligns with the required output format. The fourth result shows a JSON example with system messages and user interactions, which might be a template. The fifth result is incomplete, so not useful.\n",
      "\n",
      "Since the input data is missing, I can't proceed with the analysis. The instructions are clear: I need to review the content description, hashtags, and captions to assign codes. Without that information, any codes I assign would be arbitrary. The user might have forgotten to include the data, or maybe it's a test to see if I handle missing information correctly.\n",
      "\n",
      "I should check if there's any example data in the search results. The fourth result has a JSON example with a system message and user interactions, but that's about JavaScript code, not TikTok content. The third result's JSON examples are about properties and nested objects, which don't relate to the codebook categories.\n",
      "\n",
      "Given that the input data is absent, the correct approach is to inform the user that the necessary information is missing. However, the instructions say to provide a JSON object wrapped in <json_output> tags. But without data, I can't generate a valid JSON response. Maybe the user expects a placeholder or an error message, but according to the instructions, I should only output the JSON without any other text.\n",
      "\n",
      "Wait, the user's extra instructions say to provide the response ONLY as a JSON object within <json_output> tags. So even if the data is missing, I have to comply. But how? The codebook requires analyzing content, hashtags, and captions. Without those, I can't assign codes. Maybe the user made a mistake in the query, omitting the data. In that case, the answer should be an empty JSON object or an error. But the instructions don't mention handling missing data. \n",
      "\n",
      "Alternatively, perhaps the user intended to include the data but forgot. Since I can't proceed, the best response is to state that the input data is missing and cannot be analyzed. However, the instructions strictly require a JSON output. This is a conflict. \n",
      "\n",
      "Looking back at the search results, the third result shows a JSON object with properties like \"StringProperty\" and \"NumberProperty\". Maybe the user expects a similar structure. But without the actual data, I can't populate the codes. \n",
      "\n",
      "In conclusion, the correct response is to inform the user that the input data is missing, but since the instructions mandate a JSON output, perhaps return an empty JSON object. However, the codebook requires up to 5 codes and a reason. Without data, the reason would be that the input is missing. But the instructions say to provide only the JSON. \n",
      "\n",
      "Alternatively, maybe the user provided the data in the search results. Let me check again. The fourth search result has a JSON example with system messages and user interactions, but that's about JavaScript. The third result's JSON examples are about properties. The first result's example is about students. None of these relate to TikTok content analysis. \n",
      "\n",
      "Therefore, the answer must be that the input data is missing, but according to the instructions, I have to output a JSON. Since I can't generate valid codes without data, the JSON would be empty. But the codebook requires codes and reasons. This is a dilemma. \n",
      "\n",
      "Perhaps the user made a mistake, and the assistant should respond accordingly. However, following the instructions strictly, the assistant must output a JSON. Given that, the assistant should return a JSON object with empty codes and a reason stating the data is missing. But the instructions say to provide the response ONLY as a JSON object. So maybe:\n",
      "\n",
      "<json_output>{}</json_output>\n",
      "\n",
      "But that's not helpful. Alternatively, include a reason in the JSON. For example:\n",
      "\n",
      "<json_output>{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data (Content Description, Hashtags, Captions) is missing, preventing code assignment.\"\n",
      "}</json_output>\n",
      "\n",
      "But the codebook requires up to 5 codes and a reason. Without data, the codes array is empty, and the reason explains why. This complies with the instructions to output a JSON and explains the absence of data. \n",
      "\n",
      "Yes, that makes sense. The assistant should return a JSON with empty codes and a reason indicating missing data. This adheres to the user's instructions while handling the missing input appropriately.\n",
      "</think>\n",
      "\n",
      "<json_output>{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data (Content Description, Hashtags, Captions) is missing, preventing code assignment.\"\n",
      "}</json_output>\n",
      "    *** FAILED to process Video ID: 7351440334913604870 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 6/12 - Video ID: 7458881594665815326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with specific codes and a reason. But wait, the input data they provided is empty. The Content Description, Hashtags, and Captions are all blank. Hmm, that's a problem because I need those details to apply the codes from the codebook.\n",
      "\n",
      "First, I need to check if I missed any information. The user mentioned \"Input Data\" but didn't fill in the actual content. Without knowing what the TikTok content is about, I can't determine which codes apply. For example, if the content is about someone traveling and discovering themselves, I might use codes like JN-PG or ET-SD. But without any data, I can't make those judgments.\n",
      "\n",
      "Looking at the codebook, there are several categories like Journey Narratives, Digital Representation, Commercialization, etc. Each code has specific descriptions. But without the actual content, I can't match any of these. The user's instructions say to provide a JSON object with up to 5 codes and a reason, but the input is missing. \n",
      "\n",
      "I should also consider if there's a way to proceed despite the missing data. Maybe the user expects a placeholder or an example. But according to the instructions, I must base the analysis on the provided data. Since there's no data, I can't generate valid codes. \n",
      "\n",
      "The correct approach here is to inform the user that the input data is missing and that I can't proceed without it. However, the user's instructions strictly say to return a JSON object wrapped in <json_output> tags without any other text. But since there's no data, I can't create a meaningful JSON response. \n",
      "\n",
      "Wait, maybe the user made a mistake in providing the input. They might have intended to include the Content Description, Hashtags, and Captions but forgot. In that case, I should point out the missing information. But according to the instructions, I shouldn't include any explanations outside the JSON tags. \n",
      "\n",
      "This is a bit of a dilemma. The user wants a JSON response, but the input is incomplete. The only valid response here is to state that the input data is missing and thus no codes can be applied. However, the instructions say to provide the JSON object regardless. \n",
      "\n",
      "Alternatively, maybe the user provided the input data in a different part of the query that I'm not seeing. Let me check again. The Input Data section under the query has placeholders but no actual content. So, no, there's nothing to analyze. \n",
      "\n",
      "In conclusion, without the necessary input data, I can't apply the codebook to generate valid codes. The appropriate response is to inform the user that the input data is missing, but according to their instructions, I must return a JSON object. Since I can't do that, perhaps the best approach is to return an empty JSON object or indicate an error. However, the user's instructions are strict about the format. \n",
      "\n",
      "Wait, looking back at the user's instructions: \"Your final output MUST be ONLY a valid JSON object enclosed within <json_output> and </json_output> delimiters. Do NOT include any other text, markdown, or explanations...\" So even if there's no data, I have to return a JSON object. But how? Maybe with empty codes and a reason stating the data is missing. \n",
      "\n",
      "But the codebook requires selecting up to 5 codes based on the content. Without content, I can't select any. So perhaps the JSON should have an empty codes array and a reason explaining the lack of data. \n",
      "\n",
      "Yes, that makes sense. The JSON would look like:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Insufficient input data provided to apply codes from the codebook.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But the user's example in the query shows that the input data is supposed to be filled in. Since it's not, the response should reflect that. Therefore, the correct answer is to return a JSON object with empty codes and a reason explaining the missing data.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Insufficient input data provided to apply codes from the codebook. Content description, hashtags, and captions are required for qualitative analysis.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7458881594665815326 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 7/12 - Video ID: 7462004697453317406\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with specific codes and a reason. But wait, the input data they provided is empty. The Content Description, Hashtags, and Captions are all blank. Hmm, that's a problem because without any actual data to analyze, I can't apply the codes from the codebook.\n",
      "\n",
      "First, I need to check if I missed something. The user mentioned \"Input Data\" but didn't fill in the details. Maybe it's a mistake or a placeholder. Since there's no real data here, I can't proceed with the analysis. The codebook has various categories like Journey Narratives, Digital Representation, etc., but without content to reference, I can't assign any codes.\n",
      "\n",
      "I should also consider the instructions carefully. The user emphasized that the response must be a JSON object wrapped in <json_output> tags, nothing else. But since there's no data, I can't generate valid codes or a reason. The correct approach here is to inform the user that the input data is missing and that analysis isn't possible without it.\n",
      "\n",
      "Wait, maybe the user intended to provide data but forgot. In that case, I need to point out the missing information. However, according to the instructions, I should only return the JSON object. But since there's nothing to analyze, the JSON would be empty or invalid. That's not helpful. The best course is to state that the input data is missing and thus no codes can be assigned, but the user wants only JSON. Hmm, this is a conflict.\n",
      "\n",
      "Looking at the codebook again, all codes require specific content elements. Without any content, hashtags, or captions, I can't map anything. Therefore, the appropriate response is to return an empty JSON object or indicate that no codes apply. But the instructions say to provide up to 5 codes. Since there's no data, maybe the codes array should be empty. However, the user might expect some default or error handling. But the instructions don't mention handling missing data, so I have to follow strictly.\n",
      "\n",
      "In conclusion, the correct answer is to return a JSON object with an empty codes array and a reason stating that input data is missing. That way, it adheres to the structure required while explaining the lack of data.\n",
      "</think>\n",
      "\n",
      "<json_output>{ \"codes\": [], \"reason\": \"No input data provided for analysis. Content description, hashtags, and captions are required to apply codes from the codebook.\" }</json_output>\n",
      "    *** FAILED to process Video ID: 7462004697453317406 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 8/12 - Video ID: 7458780491345317151\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with specific codes and reasons. But wait, the input data isn't actually provided here. The user mentioned \"Content Description,\" \"Hashtags,\" and \"Captions,\" but those fields are empty. Hmm, that's a problem. Without the actual data to analyze, how can I apply the codes from the codebook?\n",
      "\n",
      "Looking at the search results, maybe there's something there that can help. Let's check the search results provided. The first result talks about JSON structures, which is relevant because the output needs to be a JSON object. The second result is a GitHub issue about escaping ampersands, which doesn't seem related. The third result explains JSON object structures, which reinforces the need for proper JSON formatting. The fourth result shows an example of a JSON array with system and user messages, which might be a template for how the JSON should look.\n",
      "\n",
      "Since the input data is missing, I can't perform the actual analysis. The user's instructions are strict: they want only a JSON object wrapped in <json_output> tags. But without the content to analyze, I can't determine the relevant codes or reasons. The codebook has various categories like Journey Narratives, Digital Representation, etc., but without knowing what the TikTok content is about, I can't map it to these codes.\n",
      "\n",
      "Wait, maybe the user expects a placeholder or an example response? The fourth search result has a JSON structure with system and user messages. Perhaps the user wants a similar structure, but according to their codebook. However, the codebook requires specific codes and reasons based on the content. Without content, any codes selected would be arbitrary.\n",
      "\n",
      "The instructions say to provide a JSON object only, no other text. But since there's no data, I can't generate a valid JSON response. The correct approach here is to inform the user that the input data is missing and that analysis can't proceed. However, the user's instructions are strict about not including any explanations outside the JSON tags. But since the data isn't provided, I can't comply with the request. \n",
      "\n",
      "Alternatively, maybe the user made a mistake and the input data is supposed to be in the query but isn't. In that case, the answer should state that the necessary information is missing. But according to the instructions, if the search results are unhelpful, answer as best as possible with existing knowledge. The search results don't provide any TikTok data to analyze, so the answer must be that the input data is missing.\n",
      "\n",
      "But the user wants a JSON object. How to handle this? The answer should be a JSON object indicating that the data is missing. For example:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"error\": \"Input data missing\",\n",
      "  \"reason\": \"Content Description, Hashtags, and Captions are required for analysis.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But the user's instructions say to provide a JSON object with codes and reasons. Since the data isn't there, the codes can't be determined. Therefore, the correct response is to inform the user that the input data is missing, but strictly following the format. However, the user's example in the query shows that the JSON should include codes and reasons. Without data, this isn't possible. \n",
      "\n",
      "In conclusion, the appropriate response is to return a JSON object stating that the input data is missing, as per the instructions to provide only a JSON object. The search results don't provide any data to analyze, so the answer must reflect that.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Input data (Content Description, Hashtags, Captions) is missing. Analysis cannot proceed without these elements to map to the codebook categories.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7458780491345317151 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 9/12 - Video ID: 7484322719320853782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on the provided system instructions and codebook. The input data includes Content Description, Hashtags, and Captions, but they're all empty here. Hmm, that's a problem. Without any actual data to analyze, how can I apply the codes from the codebook?\n",
      "\n",
      "First, I need to check if the user made a mistake in providing the input data. The Content Description, Hashtags, and Captions sections are all blank. The instructions mention that I should review these elements to determine the relevant codes. But since there's nothing there, I can't proceed with the analysis.\n",
      "\n",
      "Looking at the codebook, there are several categories like Journey Narratives, Digital Representation, etc., each with specific codes. Each code has a description that I need to match against the input data. For example, if the content description mentioned a transformative experience through travel, I would use JN-TE. But without any data, I can't identify any codes.\n",
      "\n",
      "The user also emphasized that the response must be a JSON object wrapped in <json_output> tags. They want only the JSON, no explanations. But since there's no data to analyze, the JSON would have empty fields. However, the instructions say to provide up to 5 codes. If there's no data, maybe the codes array should be empty, and the reason should explain that there's insufficient information.\n",
      "\n",
      "Wait, the user's example in the query shows that the input data is empty. So perhaps this is a test case where the input is missing. In that case, the correct approach is to return a JSON with empty codes and a reason stating that the input data is missing.\n",
      "\n",
      "But according to the instructions, I need to base the codes on the provided data. If there's no data, I can't assign any codes. Therefore, the codes array should be empty, and the reason should indicate that the input data is missing or insufficient.\n",
      "\n",
      "So the final JSON would look like:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Insufficient input data provided for analysis. Content Description, Hashtags, and Captions are empty.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But wait, the user's example in the query has empty input data. Maybe they want to see how the JSON structure should look even with empty data. The instructions say to return a single JSON object, so even with empty data, the structure must be correct.\n",
      "\n",
      "Therefore, the answer should be a JSON object with empty codes and a reason explaining the lack of data. That's the only way to comply with the user's instructions given the missing input.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"Insufficient input data provided for analysis. Content Description, Hashtags, and Captions are empty.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7484322719320853782 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 10/12 - Video ID: 7472335279052033287\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data using a provided codebook and return a JSON object with specific codes and reasons. First, I need to understand the structure of the input data. The input includes Content Description, Hashtags, and Captions, but the user hasn't provided actual data here. Wait, looking back, the user's query includes a section labeled \"Input Data\" with placeholders for Content Description, Hashtags, and Captions. But in the actual message, those fields are empty. Hmm, that's a problem. Without the actual data, how can I apply the codebook?\n",
      "\n",
      "Wait, maybe the user made a mistake in pasting the input data. Let me check again. The query says \"Analyze the following data based on the system instructions\" and then lists Input Data with placeholders. But there's no real data provided. The search results include some JSON examples and code snippets, but they don't seem related to TikTok content analysis. The user might have intended to include sample data but forgot. \n",
      "\n",
      "Since there's no actual data to analyze, I can't proceed with the coding. The instructions are clear: I need to review the Content Description, Hashtags, and Captions to assign codes. Without those elements, I can't determine which codes apply. The codebook has various categories like Journey Narratives, Digital Representation, etc., each with specific codes. For example, if the content is about personal growth through travel, I'd use JN-PG. But without knowing the content, I can't make that judgment.\n",
      "\n",
      "The user also mentioned that the response must be a JSON object wrapped in <json_output> tags. But without data, I can't generate valid codes or reasons. The search results provided don't include any TikTok data examples either. The first result is about JSON structures, the second about GitHub issues, the third about JSON schema examples, and the fourth about a system chat in JSON format. None of these relate to the TikTok analysis task.\n",
      "\n",
      "Therefore, the correct approach here is to inform the user that the input data is missing. I should respond by stating that there's no data provided to analyze and ask them to provide the necessary Content Description, Hashtags, and Captions. However, the user's instructions say to provide the response only as a JSON object within <json_output> tags. But since there's no data, I can't generate a valid JSON response. \n",
      "\n",
      "Wait, the user's instructions also mention that if the search results are empty or unhelpful, answer as best as possible with existing knowledge. But in this case, the search results aren't about TikTok data analysis. The codebook is provided, but without the input data, I can't apply it. So the appropriate response is to point out the missing data and request it. However, the user's system instructions strictly require a JSON output. \n",
      "\n",
      "This is a dilemma. The user might have intended to include sample data but forgot. Alternatively, maybe the data is in the search results. Let me check the search results again. The fourth search result has a JSON example with a system message about data visualization and a JavaScript console example. But that's not related to TikTok content analysis. The other results are about JSON structures, GitHub issues, and JSON schema examples. None of these contain TikTok data to analyze.\n",
      "\n",
      "Given that, the only possible conclusion is that the user provided an incomplete query. Therefore, the correct response is to inform them that the input data is missing and cannot proceed without it. However, the user's instructions require a JSON response. Since I can't generate a valid JSON without data, I should return an empty JSON object or an error message. But according to the instructions, the response must be a valid JSON object. \n",
      "\n",
      "Alternatively, maybe the user expects me to use the codebook to create a template JSON response. But without data, the codes and reasons would be arbitrary. That's not appropriate. The ethical approach is to inform the user of the missing data. However, the system instructions say to provide the response only as a JSON object. \n",
      "\n",
      "In this case, the best approach is to return a JSON object indicating that the input data is missing. For example:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"No input data provided for analysis.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But the user's instructions say to provide codes up to 5 and a reason. Since there's no data, the codes array is empty, and the reason explains the absence of data. This adheres to the JSON structure required while addressing the missing input.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"No input data provided for analysis. Please provide Content Description, Hashtags, and Captions to proceed with qualitative coding.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7472335279052033287 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 11/12 - Video ID: 7473437533926378759\n",
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with specific codes and reasons. But wait, the input data they provided is empty. The Content Description, Hashtags, and Captions are all blank. Hmm, that's a problem. Without any actual data to analyze, how can I apply the codes from the codebook?\n",
      "\n",
      "First, I need to check if there's any data in the search results that might be relevant. The search results include information about JSON structures, some GitHub issues, a JSON object structure example, and a Hugging Face dataset with system chat examples. None of these seem related to TikTok content analysis or the codebook provided. The user's query is about qualitative coding of TikTok data, but the search results don't contain any TikTok data or examples to work with.\n",
      "\n",
      "Since the input data is missing, I can't perform the analysis as instructed. The codebook requires me to look at Content Description, Hashtags, and Captions to assign codes. Without those elements, I can't determine which codes apply. For example, if the content was about a transformative travel experience, I might use JN-TE. But without knowing the content, I can't make that judgment.\n",
      "\n",
      "The user also mentioned that the response should be a JSON object wrapped in <json_output> tags. But since there's no data to analyze, creating such a JSON would be impossible. The instructions are strict about not including any other text outside the JSON tags, so I can't explain the issue here. However, the user might have intended to provide data but forgot. In that case, I should inform them that the data is missing and I can't proceed.\n",
      "\n",
      "Looking at the search results again, maybe there's a misunderstanding. The user might have included the search results as part of the input data, but they don't seem to relate. The GitHub issue about ampersands in tags and the JSON examples don't align with the codebook's categories. The Hugging Face example is about a JavaScript console, which is unrelated.\n",
      "\n",
      "Therefore, the correct approach is to inform the user that the input data is missing and that I can't perform the analysis without it. However, since the user's instructions say to provide the response only as a JSON object, I need to comply with that. But how? If there's no data, the JSON would be empty or invalid. The codebook requires up to 5 codes, but without data, I can't assign any.\n",
      "\n",
      "Wait, maybe the user made a mistake in formatting the query. The input data section is empty, so perhaps they intended to include actual data but forgot. In that case, the answer should be an empty JSON object or a message indicating insufficient data. But according to the instructions, I must return a JSON object. However, an empty JSON object might not be valid. Alternatively, I could return a JSON with an error message, but the instructions say to only include the JSON without any other text.\n",
      "\n",
      "This is a bit of a dilemma. The user's instructions are strict, but the input data is missing. The correct response, following the instructions, would be to return an empty JSON object. But maybe the user expects me to use the search results as the input data. Let me check the search results again.\n",
      "\n",
      "Looking at the search results, the GitHub issue [2] has some content about ampersands in tags and spelling mistakes. The Hugging Face example [4] includes a system message about data visualization and a JavaScript console example. The JSON examples in [1] and [3] are about JSON structures. None of these relate to TikTok content analysis or the codebook provided. Therefore, even if I tried to use the search results as input data, they don't fit the codebook's categories.\n",
      "\n",
      "In conclusion, the input data is missing, and the search results don't provide relevant information. The appropriate response is to inform the user that the data is insufficient, but according to the instructions, I must return a JSON object. Since I can't assign any codes without data, the JSON would be empty. However, an empty JSON object might not be valid. Alternatively, I could return a JSON with an error message, but the instructions prohibit any text outside the JSON tags.\n",
      "\n",
      "Given the strict instructions, the only compliant response is an empty JSON object. But that's not helpful. Alternatively, maybe the user intended to provide data but forgot, and I should point that out. However, the instructions say to provide the response only as a JSON object. Therefore, the correct answer is to return an empty JSON object, even though it's not useful. But perhaps the user expects me to use the search results as the input data. Let me check again.\n",
      "\n",
      "The search result [4] has a system message about data visualization and a JavaScript example. If I were to analyze that, maybe I could assign codes. For example, the JavaScript code could relate to TA-AC (Accessibility) if it's using templates or code snippets. But the codebook's TA-AC is about ease of expression and re-use of content, which might not apply here. The system message mentions adhering to JSON format, which could relate to DR-PSC (Platform-Specific Content) if it's about formatting for TikTok. But the example is about a JavaScript console, not TikTok.\n",
      "\n",
      "This is too speculative. Without explicit data, it's impossible to apply the codebook accurately. Therefore, the correct response is to inform the user that the input data is missing, but since I must return a JSON object, I have to comply. However, an empty JSON object isn't valid. Maybe the user expects me to use the search results as the input data, but they don't align with the codebook. In that case, the JSON would have no codes, but the instructions require up to 5 codes. This is a contradiction.\n",
      "\n",
      "Given all this, the only possible compliant response is an empty JSON object, even though it's not meaningful. Alternatively, the user might have made a mistake, and I should proceed with the available data. But without data, I can't. Therefore, the answer is an empty JSON object.\n",
      "</think>\n",
      "\n",
      "<json_output>{}</json_output>\n",
      "    *** FAILED to process Video ID: 7473437533926378759 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "Processing 12/12 - Video ID: 7467848608411290898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Could not parse JSON from response. Error: Expecting value: line 1 column 1 (char 0)\n",
      "    Raw Text Received: <think>\n",
      "Okay, let's tackle this query step by step. The user wants me to analyze some TikTok data based on a provided codebook and return a JSON object with codes, reasons, and other details. But wait, the input data they provided is empty. The Content Description, Hashtags, and Captions are all blank. Hmm, that's a problem because I need those to apply the codes from the codebook.\n",
      "\n",
      "First, I need to check if there's any actual data to work with. The user mentioned \"Input Data\" but didn't include any content. Without the content, hashtags, or captions, I can't determine which codes apply. The codebook has various categories like Journey Narratives, Digital Representation, etc., each with specific codes. Each code requires certain elements in the content to be relevant.\n",
      "\n",
      "For example, if the content had a story about personal growth through travel, I might use JN-PG. If there were hashtags related to tourism, CA-TC could apply. But without any data, I can't make those connections. The instructions say to provide a JSON object only, but there's nothing to analyze. \n",
      "\n",
      "I should also consider if the user made a mistake in not providing the data. Maybe they intended to include it but forgot. In that case, the best approach is to inform them that the input data is missing and I can't proceed. However, the user's instructions are strict: they want only a JSON object wrapped in <json_output> tags. But since there's no data, creating a valid JSON response isn't possible. \n",
      "\n",
      "Alternatively, maybe the user expects a placeholder or an example. But according to the instructions, I must base the analysis on the provided data. Since there's none, I can't generate meaningful codes or reasons. The correct response here is to state that the input data is missing and thus no analysis can be performed. However, the user's instructions say to provide only the JSON object without any other text. This is a conflict because I can't create a valid JSON response without data.\n",
      "\n",
      "Wait, looking back at the query, the user included a section labeled \"Input Data\" with placeholders but no actual content. So technically, the input data is empty. In such a case, the appropriate response would be to return an empty JSON object or indicate that no data was provided. But according to the instructions, the JSON must be valid and enclosed in the specified tags. An empty JSON object would be {}, but the user might expect some structure. However, without data, there's nothing to code. \n",
      "\n",
      "Another angle: maybe the user intended to test if I can handle missing data. In that case, the correct approach is to return a JSON object with an error message or a note that data is missing. But the instructions say to provide codes and reasons based on the data. Since there's no data, the codes and reasons can't be determined. Therefore, the JSON should reflect that no analysis was possible due to missing input. \n",
      "\n",
      "But the user's instructions are strict about the format. They want only the JSON object. So perhaps the answer is to return a JSON object with an empty codes array and a reason stating that no data was provided. However, the codebook requires up to 5 codes, but without data, none can be applied. The reason would explain that. \n",
      "\n",
      "So, putting it all together, the JSON would look like:\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"No input data provided for analysis. Content description, hashtags, and captions are required to apply codes from the codebook.\"\n",
      "}\n",
      "</json_output>\n",
      "\n",
      "But wait, the user's example in the query shows a JSON structure with \"codes\", \"reason\", and possibly other fields. The codebook mentions up to 5 codes, but in this case, none can be selected. The reason must justify the code choices, but since there are none, the reason explains the absence of data. \n",
      "\n",
      "Yes, that makes sense. The JSON should have an empty codes array and a reason indicating the lack of input data. This adheres to the user's instructions of providing only the JSON object without any extra text. Even though the data is missing, the response is still a valid JSON object as required.\n",
      "</think>\n",
      "\n",
      "<json_output>\n",
      "{\n",
      "  \"codes\": [],\n",
      "  \"reason\": \"No input data provided for analysis. Content description, hashtags, and captions are required to apply codes from the codebook.\"\n",
      "}\n",
      "</json_output>\n",
      "    *** FAILED to process Video ID: 7467848608411290898 ***\n",
      "Stored 'failed_ids_file' (str)\n",
      "\n",
      "--- Finalizing Results ---\n",
      "\n",
      "--- Script finished ---\n",
      "Total successfully processed: 10588 videos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- MODIFIED: Hardened, Multi-Stage JSON Extraction Function ---\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Finds and loads the first valid JSON object from a string.\n",
    "    Priority 1: Look for content within <json_output> delimiters.\n",
    "    Priority 2: Fallback to finding the outermost JSON object {}.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Priority 1: Look for content within <json_output> tags\n",
    "        start_tag = \"<json_output>\"\n",
    "        end_tag = \"</json_output>\"\n",
    "        tag_start_index = text.find(start_tag)\n",
    "        tag_end_index = text.rfind(end_tag)\n",
    "\n",
    "        if tag_start_index != -1 and tag_end_index != -1:\n",
    "            json_str = text[tag_start_index + len(start_tag):tag_end_index].strip()\n",
    "            return json.loads(json_str)\n",
    "\n",
    "        # Priority 2: Fallback to finding the first and last curly brace\n",
    "        start_index = text.find('{')\n",
    "        end_index = text.rfind('}')\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            json_str = text[start_index:end_index+1]\n",
    "            return json.loads(json_str)\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        # This error message is crucial for debugging.\n",
    "        print(f\"    Could not parse JSON from response. Error: {e}\")\n",
    "        print(f\"    Raw Text Received: {text}\") # Print the raw text that failed\n",
    "        return None\n",
    "    \n",
    "    # If no JSON is found at all, return None\n",
    "    return None\n",
    "\n",
    "# --- MODIFIED: Core analysis function with retry logic and hardened prompt ---\n",
    "def analyze_tiktok_video(row, headers):\n",
    "    \"\"\"\n",
    "    Analyzes a single row of TikTok data with a hardened prompt and retry logic.\n",
    "    \"\"\"\n",
    "    codebook = \"\"\"\n",
    "    \n",
    "   ## Codebook of the Qualitative Content Analysis ##\n",
    "\n",
    "    **Category: Journey Narratives**\n",
    "    - Code: JN-TE, Label: Transformative Experiences, Description: Self-actualization through travel.\n",
    "    - Code: JN-EP, Label: Episodic Progress, Descrition: Narrative of experiences, milestones while traveling.\n",
    "    - Code: JN-PG, Label: Personal Growth, Description: Insights and achievements through travel.\n",
    "\n",
    "    **Category: Digital Representation**\n",
    "    - Code: DR-VS, Label: Visual Storytelling, Description: Emphasize visual appeal, e.g., coastal landscapes, city lines, and airplane flights.\n",
    "    - Code: DR-IE, Label: Idealization of Experiences, Description: The idealized version of the future, career, and destinations.\n",
    "    - Code: DR-CA, Label: Cultural Authenticity, Description: The code showcases local experiences, cultural appropriation, or superficial representation.\n",
    "    - Code: DR-PSC, Label: Platform-Specific Content, Description: Content formatted according to TikTok grammar and logic.\n",
    "\n",
    "    **Category: Commercialization**\n",
    "    - Code: CA-TC, Label: Tourism and Commerce, Description: Destination promotion content may contribute to over-tourism issues.\n",
    "    - Code: CA-PC, Label: Promotional Content, Description: Affiliated links or product placement in the content.\n",
    "\n",
    "    **Category: Symbolism**\n",
    "    - Code: SY-SL, Label: Symbolic Imagery, Description: Symbolic representation: e.g., women in bikinis represent leisure activities.\n",
    "    - Code: SY-RB, Label: Rituals, Description: The code represents local traditions, e.g., Muslim broadcasting of psalms at 6 a.m.\n",
    "\n",
    "    **Category: Existential Themes**\n",
    "    - Code: ET-SD, Label: Self-Discovery, Description: Knowledge acquisition, discovery.\n",
    "    - Code: ET-PM, Label: Purpose and Meaning, Description: Finding a meaning in the activity.\n",
    "    - Code: ET-SG, Label: Spiritual Growth, Description: The notion of becoming a better version of oneself.\n",
    "    - Code: ET-IC, Label: Identity Construction, Description: Narratives that aim to construct identity online.\n",
    "    - Code: ET-PF, Label: Personal & Spatial Freedom, Description: The freedom through mobility, the perception that the whole world is open for exploration.\n",
    "\n",
    "    **Category: Hedonism**\n",
    "    - Code: HE-SA, Label: Sport Activities, Description: The active type of recreational consumption, e.g., surfing, cycling, paragliding.\n",
    "    - Code: HE-CE, Label: Culinary Experiences, Description: Projection of food consumption, preparation, or purchase.\n",
    "    - Code: HE-SE, Label: Shared Cultural Experiences & Bonding, Description: Experiences of pleasure and sensory gratification include festivals, carnivals, and performances.\n",
    "\n",
    "    **Category: TikTok Affordances**\n",
    "    - Code: TA-AC, Label: Accessibility (e.g., templates), Description: Ease of expression and re-use of content.\n",
    "    - Code: TA-DI, Label: Discoverability (e.g., hashtags, For You Page, audios), Description: Features that enhance content discoverability, enabling the reach of wider audiences beyond immediate followers.\n",
    "    - Code: TA-RL, Label: Relatability (trends, challenges), Description: Dialogic content that resonates with and encourages viewer self-identification and participation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The system prompt is now highly structured to guide the model.\n",
    "    system_message_content = f\"\"\"\n",
    "    You are a qualitative coder. Your task is to analyze the provided TikTok data and return a single, valid JSON object.\n",
    "\n",
    "    **Instructions:**\n",
    "    1.  Carefully review the Content Description, Hashtags, and Captions below.\n",
    "    2.  Based on the Codebook provided, determine the most relevant codes (up to 5).\n",
    "    3.  Formulate a brief `reason` that explains and justifies your code choices.\n",
    "    4.  Your final output MUST be ONLY a valid JSON object enclosed within `<json_output>` and `</json_output>` delimiters. Do NOT include any other text, markdown, or explanations like `<think>` outside these delimiters.\n",
    "\n",
    "    **Codebook:**\n",
    "    {codebook}\n",
    "    \"\"\"\n",
    "    \n",
    "    # The user prompt uses the \"sandwich\" technique, placing the data between instructions.\n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following data based on the system instructions:\n",
    "\n",
    "    **Input Data:**\n",
    "    - Content Description: {row.get('desc', 'N/A')}\n",
    "    - Hashtags: {row.get('hashtagNames', 'N/A')}\n",
    "    - Captions: {row.get('stickersText', 'N/A')}\n",
    "\n",
    "    Remember, provide your response ONLY as a JSON object wrapped in <json_output> tags.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message_content}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    payload = {\"model\": \"sonar-reasoning\", \"messages\": messages, \"max_tokens\": 2048, \"temperature\": 0.1}\n",
    "\n",
    "    # The robust retry logic remains.\n",
    "    max_retries = 3\n",
    "    base_delay = 2\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\"https://api.perplexity.ai/chat/completions\", headers=headers, json=payload, timeout=60)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                raw_output = response.json()['choices'][0]['message']['content']\n",
    "                return extract_json_from_text(raw_output)\n",
    "            \n",
    "            elif response.status_code == 429:\n",
    "                delay = (attempt + 1) * 10\n",
    "                print(f\"    Rate limit hit. Waiting {delay}s before retrying...\")\n",
    "                time.sleep(delay)\n",
    "            elif 500 <= response.status_code < 600:\n",
    "                delay = base_delay * (2 ** attempt)\n",
    "                print(f\"    Server Error {response.status_code}. Retrying in {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"    Client/API Error {response.status_code}: {response.text}\")\n",
    "                return None\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            delay = base_delay * (2 ** attempt)\n",
    "            print(f\"    Request Exception: {e}. Retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "    print(f\"    All {max_retries} retries failed for Video ID {row.get('videoId', 'N/A')}.\")\n",
    "    return None\n",
    "\n",
    "# --- Main execution block with CHECKPOINTING ---\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    sonar_key = os.getenv(\"SONAR_KEY\")\n",
    "    if not sonar_key: raise ValueError(\"Error: SONAR_KEY not found in .env file.\")\n",
    "    \n",
    "    print(\"SONAR_KEY loaded successfully.\")\n",
    "    headers = {\"Authorization\": f\"Bearer {sonar_key}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    output_json_file = 'analysis_results.json'\n",
    "    failed_ids_file = 'failed_videos.txt'\n",
    "    \n",
    "    try:\n",
    "        text_cols = ['desc', 'hashtagNames', 'stickersText']\n",
    "        for col in text_cols:\n",
    "            if col in dataset.columns:\n",
    "                dataset[col] = dataset[col].fillna('')\n",
    "        \n",
    "       # Checkpointing logic to resume from where you left off\n",
    "        successful_results = []\n",
    "        processed_ids = set()\n",
    "\n",
    "        if os.path.exists(output_json_file):\n",
    "            print(f\"Found existing results file: '{output_json_file}'. Resuming...\")\n",
    "            try:\n",
    "                with open(output_json_file, 'r', encoding='utf-8') as f:\n",
    "                    successful_results = json.load(f)\n",
    "                    processed_ids = {item['videoId'] for item in successful_results if 'videoId' in item}\n",
    "                print(f\"Loaded {len(successful_results)} previously processed videos.\")\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                print(\"Warning: Could not read existing results file. Starting from scratch.\")\n",
    "                successful_results = []\n",
    "                processed_ids = set()\n",
    "\n",
    "        all_rows = dataset.to_dict(orient='records')\n",
    "        rows_to_process = [row for row in all_rows if row['videoId'] not in processed_ids]\n",
    "        \n",
    "        if not rows_to_process:\n",
    "            print(\"All videos have already been processed. Exiting.\")\n",
    "        else:\n",
    "            print(f\"\\n--- Starting analysis on {len(rows_to_process)} remaining videos ---\")\n",
    "            \n",
    "            for i, row in enumerate(rows_to_process):\n",
    "                print(f\"Processing {i+1}/{len(rows_to_process)} - Video ID: {row['videoId']}\")\n",
    "                result = analyze_tiktok_video(row, headers)\n",
    "                \n",
    "                if result:\n",
    "                    result['videoId'] = row['videoId']\n",
    "                    successful_results.append(result)\n",
    "                    # Checkpoint every 50 results\n",
    "                    if (i + 1) % 50 == 0:\n",
    "                        print(f\"    Checkpointing... saving {len(successful_results)} results.\")\n",
    "                        with open(output_json_file, 'w', encoding='utf-8') as f:\n",
    "                            json.dump(successful_results, f, ensure_ascii=False, indent=4)\n",
    "                else:\n",
    "                    print(f\"    *** FAILED to process Video ID: {row['videoId']} ***\")\n",
    "                    with open(failed_ids_file, 'a', encoding='utf-8') as f:\n",
    "                        f.write(f\"{row['videoId']}\\n\")\n",
    "                        %store failed_ids_file\n",
    "\n",
    "        print(\"\\n--- Finalizing Results ---\")\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(successful_results, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(f\"\\n--- Script finished ---\")\n",
    "        print(f\"Total successfully processed: {len(successful_results)} videos.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during main execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b530e",
   "metadata": {},
   "source": [
    "#Second phase of coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e46f9be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONAR_KEY loaded successfully.\n",
      "Found existing results file: 'needs_results.json'. Resuming...\n",
      "Loaded 10584 previously processed videos.\n",
      "\n",
      "--- Starting analysis on 4 remaining videos ---\n",
      "Processing 1/4 - Video ID: 7058281179367083269\n",
      "    *** FAILED to process Video ID: 7058281179367083269 ***\n",
      "Processing 2/4 - Video ID: 7158159636024118533\n",
      "    *** FAILED to process Video ID: 7158159636024118533 ***\n",
      "Processing 3/4 - Video ID: 7215794166012366122\n",
      "Processing 4/4 - Video ID: 7205144184632659206\n",
      "    *** FAILED to process Video ID: 7205144184632659206 ***\n",
      "\n",
      "--- Finalizing Results ---\n",
      "\n",
      "--- Script finished ---\n",
      "Total successfully processed: 10585 videos.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Finds and loads the first valid JSON object from a string,\n",
    "    looking for content within <json_output> delimiters if present.\n",
    "    Falls back to curly brace matching if delimiters are not found or invalid.\n",
    "    \"\"\"\n",
    "    start_tag = \"<json_output>\"\n",
    "    end_tag = \"</json_output>\"\n",
    "    tag_start_index = text.find(start_tag)\n",
    "    tag_end_index = text.rfind(end_tag)\n",
    "\n",
    "    if tag_start_index != -1 and tag_end_index != -1:\n",
    "        json_str_candidate = text[tag_start_index + len(start_tag):tag_end_index].strip()\n",
    "        try:\n",
    "            return json.loads(json_str_candidate)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    # Priority 2: Fallback to finding the first and last curly brace\n",
    "    try:\n",
    "        start_index = text.find('{')\n",
    "        end_index = text.rfind('}')\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            json_str = text[start_index:end_index+1]\n",
    "            return json.loads(json_str)\n",
    "    except (json.JSONDecodeError, IndexError) as e:\n",
    "        print(f\"Could not parse JSON from response: {text}, Error: {e}\")\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def analyze_tiktok_video_element(row, headers):\n",
    "    \"\"\"\n",
    "    Performs second-step coding using a defined framework and a dedicated LLM.\n",
    "    Makes direct API calls using requests with provided headers.\n",
    "    \"\"\"\n",
    "    system_message_content = \"\"\"\n",
    "    You are a qualitative coder performing a second-order classification. Your task is to analyze a set of pre-assigned codes from a TikTok video and map them to a single 'Element' and its corresponding 'Primary Need' from the provided framework. \n",
    "    Important: Regardless of the input language, acknowledge the language but analyze in English using the same framework.\n",
    "\n",
    "    **## THEORETICAL FRAMEWORK ##**\n",
    "\n",
    "    You must use the following Hierarchy of Needs for each element:\n",
    "\n",
    "    {\n",
    "        \"Worker\": {\"Basic\": \"Location independence, internet connection\", \"Safety\": \"Diversification of income, stable work environment\", \"Social\": \"Professional networking, co-working spaces\", \"Esteem\": \"Career growth, skill development\", \"Self-actualization\": \"Work-life balance, meaningful work\"},\n",
    "        \"Tourist\": {\"Basic\": \"Accommodation, food\", \"Safety\": \"Comfortable and affordable travel\", \"Social\": \"Meeting locals and other travelers\", \"Esteem\": \"Unique experiences, cultural immersion\", \"Self-actualization\": \"Personal growth through travel\"},\n",
    "        \"Migrant\": {\"Basic\": \"Legal status, housing\", \"Safety\": \"Understanding local laws, healthcare access\", \"Social\": \"Integration into the local community\", \"Esteem\": \"Cultural adaptation, language skills\", \"Self-actualization\": \"Sense of belonging in a new place\"},\n",
    "        \"Pilgrim\": {\"Basic\": \"Finding purpose in travel\", \"Safety\": \"Spiritual or emotional security\", \"Social\": \"Connecting with like-minded individuals\", \"Esteem\": \"Personal transformation\", \"Self-actualization\": \"Achieving life goals, enlightenment\"}\n",
    "    }\n",
    "\n",
    "    **## YOUR TASK ##**\n",
    "\n",
    "    Based on the input codes provided by the user, produce a single JSON object as output. Your output MUST be enclosed within `<json_output>` and `</json_output>` delimiters.\n",
    "\n",
    "    The JSON must contain:\n",
    "    - \"reasoning\": A concise explanation for why you chose the element, based on the input codes.\n",
    "    - \"element\": One of the four elements (Worker, Tourist, Migrant, Pilgrim).\n",
    "    - \"need\": The primary need (Basic, Safety, Social, Esteem, Self-actualization) demonstrated in the content.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Analyze the following codes and provide your classification.\n",
    "    Reason: {row.get('reason', 'N/A')}\n",
    "    Input Codes: {row.get('codes', 'N/A')}\n",
    "    Video ID: {row.get('videoId', 'N/A')}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message_content},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"sonar-reasoning\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.2\n",
    "    }\n",
    "\n",
    "    \n",
    "    # The robust retry logic remains.\n",
    "    max_retries = 3\n",
    "    base_delay = 2\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\"https://api.perplexity.ai/chat/completions\", headers=headers, json=payload, timeout=60)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                raw_output = response.json()['choices'][0]['message']['content']\n",
    "                return extract_json_from_text(raw_output)\n",
    "            \n",
    "            elif response.status_code == 429:\n",
    "                delay = (attempt + 1) * 10\n",
    "                print(f\"    Rate limit hit. Waiting {delay}s before retrying...\")\n",
    "                time.sleep(delay)\n",
    "            elif 500 <= response.status_code < 600:\n",
    "                delay = base_delay * (2 ** attempt)\n",
    "                print(f\"    Server Error {response.status_code}. Retrying in {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"    Client/API Error {response.status_code}: {response.text}\")\n",
    "                return None\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            delay = base_delay * (2 ** attempt)\n",
    "            print(f\"    Request Exception: {e}. Retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "    print(f\"    All {max_retries} retries failed for Video ID {row.get('videoId', 'N/A')}.\")\n",
    "    return None\n",
    "\n",
    "def process_analysis_results(file_path):\n",
    "    \"\"\"\n",
    "    Reads the analysis_results.json file and returns the data as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON from {file_path}.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error while processing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main execution block with CHECKPOINTING ---\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    sonar_key = os.getenv(\"SONAR_KEY\")\n",
    "    if not sonar_key: raise ValueError(\"Error: SONAR_KEY not found in .env file.\")\n",
    "    \n",
    "    print(\"SONAR_KEY loaded successfully.\")\n",
    "    headers = {\"Authorization\": f\"Bearer {sonar_key}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    output_json_file = 'needs_results.json'\n",
    "    failed_ids_file = 'failed_needs_ids.txt'\n",
    "    \n",
    "    try:\n",
    "        # Checkpointing logic to resume from where you left off\n",
    "        successful_results = []\n",
    "        processed_ids = set()\n",
    "        \n",
    "        if os.path.exists(output_json_file):\n",
    "            print(f\"Found existing results file: '{output_json_file}'. Resuming...\")\n",
    "            try:\n",
    "                with open(output_json_file, 'r', encoding='utf-8') as f:\n",
    "                    successful_results = json.load(f)\n",
    "                    processed_ids = {item['videoId'] for item in successful_results if 'videoId' in item}\n",
    "                print(f\"Loaded {len(successful_results)} previously processed videos.\")\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                print(\"Warning: Could not read existing results file. Starting from scratch.\")\n",
    "                successful_results = []\n",
    "                processed_ids = set()\n",
    "        \n",
    "        # Load the dataset from analysis_results.json\n",
    "        all_rows = process_analysis_results('analysis_results.json')\n",
    "        rows_to_process = [row for row in all_rows if row.get('videoId', 'N/A') not in processed_ids]\n",
    "        \n",
    "        if not rows_to_process:\n",
    "            print(\"All videos have already been processed. Exiting.\")\n",
    "        else:\n",
    "            print(f\"\\n--- Starting analysis on {len(rows_to_process)} remaining videos ---\")\n",
    "            \n",
    "            for i, row in enumerate(rows_to_process):\n",
    "                print(f\"Processing {i+1}/{len(rows_to_process)} - Video ID: {row.get('videoId', 'N/A')}\")\n",
    "                result = analyze_tiktok_video_element(row, headers)\n",
    "                \n",
    "                if result:\n",
    "                    result['videoId'] = row.get('videoId', 'N/A')\n",
    "                    successful_results.append(result)\n",
    "                    # Checkpoint every 50 results\n",
    "                    if (i + 1) % 50 == 0:\n",
    "                        print(f\"    Checkpointing... saving {len(successful_results)} results.\")\n",
    "                        with open(output_json_file, 'w', encoding='utf-8') as f:\n",
    "                            json.dump(successful_results, f, ensure_ascii=False, indent=4)\n",
    "                else:\n",
    "                    print(f\"    *** FAILED to process Video ID: {row.get('videoId', 'N/A')} ***\")\n",
    "                    with open(failed_ids_file, 'a', encoding='utf-8') as f:\n",
    "                        f.write(f\"{row.get('videoId', 'N/A')}\\n\")\n",
    "        \n",
    "        print(\"\\n--- Finalizing Results ---\")\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(successful_results, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(f\"\\n--- Script finished ---\")\n",
    "        print(f\"Total successfully processed: {len(successful_results)} videos.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during main execution: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f95a0b",
   "metadata": {},
   "source": [
    "#analysis if failed ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa71477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed analysis_results entries:\n",
      "{'codes': ['JN-EP', 'JN-PG', 'DR-PSC', 'ET-PF', 'TA-DI'], 'reason': 'A 3 hÃ³napos utazÃ¡s narratÃ­vÃ¡ja epizÃ³dos fejlÅ‘dÃ©st mutat (JN-EP), mÃ­g a hÃ¡tizsÃ¡kkal valÃ³ utazÃ¡s szemÃ©lyes nÃ¶vekedÃ©st jelkÃ©pez (JN-PG). A platform-specifikus tartalom (DR-PSC) a TikTok hashtagjeinek hasznÃ¡latÃ¡ban nyilvÃ¡nul meg (#utazas, #digitalnomad). Az utazÃ¡s szabadsÃ¡ga (ET-PF) a tÃ©rbeli mobilitÃ¡s Ã©s a digitÃ¡lis nomÃ¡d Ã©letmÃ³d Ã¶sszefÃ¼ggÃ©sÃ©ben Ã©rtelmezhetÅ‘. A felfedezhetÅ‘sÃ©g (TA-DI) a hashtag-stratÃ©gia rÃ©vÃ©n biztosÃ­tja a tartalom elÃ©rhetÅ‘sÃ©gÃ©t a kÃ¶zÃ¶nsÃ©g szÃ¡mÃ¡ra.', 'videoId': 7058281179367083269}\n",
      "{'codes': ['DR-CA', 'DR-PSC', 'ET-PM', 'TA-DI', 'TA-RL'], 'reason': \"Le contenu met en avant une expÃ©rience locale (sauvetage d'un poisson Ã  Guadeloupe) avec des hashtags gÃ©olocalisÃ©s (#guadeloupe, #caraibes), ce qui renvoie Ã  la **DR-CA** (authenticitÃ© culturelle). La structure courte et les hashtags visent une diffusion large sur TikTok (**DR-PSC**, **TA-DI**). L'action de sauvetage symbolise une quÃªte de sens (**ET-PM**), tandis que le scÃ©nario relatable encourage l'engagement (**TA-RL**).\", 'videoId': 7158159636024118533}\n",
      "{'codes': ['DR-PSC', 'ET-PF', 'JN-TE', 'TA-DI', 'ET-SD'], 'reason': \"The content emphasizes TikTok-specific engagement through hashtags like #traveltoktok (DR-PSC), aligns with the digital nomad lifestyle's emphasis on spatial freedom (ET-PF), frames travel as a transformative experience (JN-TE), leverages discoverability features via hashtags (TA-DI), and implies self-discovery through lifestyle changes (ET-SD).\", 'videoId': 7215794166012366122}\n",
      "{'codes': ['JN-PG', 'ET-PF', 'ET-IC', 'ET-PM', 'DR-IE'], 'reason': 'The content emphasizes personal growth through travel (JN-PG), prioritizes spatial freedom over traditional stability (ET-PF), constructs a digital nomad identity (ET-IC), seeks purpose in lifestyle choices (ET-PM), and idealizes the nomadic lifestyle as superior to conventional paths (DR-IE).', 'videoId': 7205144184632659206}\n",
      "\n",
      "Failed dataset entries:\n",
      "{'authorId': 'fanni_friedrich', 'commentCount': 47, 'dateTime': '2022-01-28 15:35:51', 'desc': '3 hÃ³nap 2 percben #utazas #digitalnomad', 'diggCount': 9639, 'duetEnabled': False, 'duetFromId': 0, 'hashtagNames': 'utazas, digitalnomad', 'stickersText': '3 hÃ³napja vagyunk Ãºton egyetlen hÃ¡tizsÃ¡kkal ðŸ§³, 3 hÃ³napja vagyunk Ãºton\\nMi tÃ¶rtÃ©nt eddig?', 'musicAlbum': nan, 'musicAuthorName': 'Fanni Friedrich', 'musicId': 7.058281179148979e+18, 'musicTitle': 'original sound', 'playCount': 125100, 'shareCount': 75, 'videoId': '7058281179367083269', 'videoLink': 'https://www.tiktok.com/@6955057330317394950/video/7058281179367083269'}\n",
      "{'authorId': 'nanoutravel13225', 'commentCount': 306, 'dateTime': '2022-10-24 20:15:19', 'desc': 'petit poisson Ã©tÃ© bloquer dans la bouteille ðŸ¥º #enmer #guadeloupe #vacation #travellife #voyage #caraibes #amazing #poisson #sauvetage #sauvetageanimaux #poissontropicaux #mignonnerie ', 'diggCount': 235200, 'duetEnabled': True, 'duetFromId': 0, 'hashtagNames': 'enmer, guadeloupe, vacation, travellife, voyage, caraibes, amazing, poisson, sauvetage, sauvetageanimaux, poissontropicaux, mignonnerie', 'stickersText': \"petit sauvetage d'un petit poisson ðŸŸ \", 'musicAlbum': nan, 'musicAuthorName': 'favsoundds', 'musicId': 6.930708960270224e+18, 'musicTitle': 'sign of the times', 'playCount': 2400000, 'shareCount': 157, 'videoId': '7158159636024118533', 'videoLink': 'https://www.tiktok.com/@6577829667331686406/video/7158159636024118533'}\n",
      "{'authorId': 'gabby_marcellus', 'commentCount': 20, 'dateTime': '2023-03-29 03:46:54', 'desc': 'The best plan B ive ever had. #digitalnomad #traveltok #traveltoktok #travelgirl #digitalnomadlife #digitalnomadgirl #digitalnomadlifestyle ', 'diggCount': 422, 'duetEnabled': True, 'duetFromId': 0, 'hashtagNames': 'digitalnomad, traveltok, traveltoktok, travelgirl, digitalnomadlife, digitalnomadgirl, digitalnomadlifestyle', 'stickersText': nan, 'musicAlbum': nan, 'musicAuthorName': 'gabrielle marcellus', 'musicId': 7.215794194361699e+18, 'musicTitle': 'original sound', 'playCount': 2991, 'shareCount': 1, 'videoId': '7215794166012366122', 'videoLink': 'https://www.tiktok.com/@6812090796558517254/video/7215794166012366122'}\n",
      "{'authorId': 'lauraabornstein', 'commentCount': 30, 'dateTime': '2023-02-28 09:59:25', 'desc': '#CapCut I\\'d rather work my ass off and be broke for a while to achieve a life that fulfills me, instead of working for 40 years being unhappy for the sake of stability. I will alwats prioritize travel and my happiness and fulfillment over \"stability\" and what I believe to be a false sense of security. No hate if you\\'re priorities are different! But respect mine aswell ðŸ˜Œ #digitalnomads #digitalnomadgirl #digitalnomadlifestyle #traveldigitalnomad #digitalnomadtravel #travellifeâœˆï¸ #travellifestyle #travelliving #workandtravel ', 'diggCount': 401, 'duetEnabled': True, 'duetFromId': 0, 'hashtagNames': 'capcut, digitalnomads, digitalnomadgirl, digitalnomadlifestyle, traveldigitalnomad, digitalnomadtravel, travellifeâœˆï¸, travellifestyle, travelliving, workandtravel', 'stickersText': '\"You\\'re never going to find a job that allows you to travel so much. You should settle down\", Travel or settle down? âœˆï¸ðŸŒ', 'musicAlbum': nan, 'musicAuthorName': 'Laura ðŸŒ Adventure travel', 'musicId': 7.205144201384775e+18, 'musicTitle': 'sonido original', 'playCount': 2187, 'shareCount': 1, 'videoId': '7205144184632659206', 'videoLink': 'https://www.tiktok.com/@6867118736861971461/video/7205144184632659206'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Hardcoded list of the 4 still failing video IDs\n",
    "failed_video_ids = [\n",
    "    '7058281179367083269',\n",
    "    '7158159636024118533',\n",
    "    '7215794166012366122',\n",
    "    '7205144184632659206'\n",
    "]\n",
    "\n",
    "# Load the dataset from CSV, ensuring videoId is read as string\n",
    "dataset = pd.read_csv('../csv/unique_videos_df.csv', dtype={'videoId': str})\n",
    "\n",
    "# Load analysis_results.json\n",
    "with open('analysis_results.json', 'r', encoding='utf-8') as f:\n",
    "    analysis_results = json.load(f)\n",
    "\n",
    "# Filter entries for failed video IDs from analysis_results\n",
    "failed_analysis_results = [item for item in analysis_results if str(item.get('videoId', '')) in failed_video_ids]\n",
    "\n",
    "# Filter entries for failed video IDs from dataset\n",
    "failed_dataset_entries = dataset[dataset['videoId'].isin(failed_video_ids)].to_dict(orient='records')\n",
    "\n",
    "print(\"\\nFailed analysis_results entries:\")\n",
    "for entry in failed_analysis_results:\n",
    "    print(entry)\n",
    "\n",
    "print(\"\\nFailed dataset entries:\")\n",
    "for entry in failed_dataset_entries:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc59af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-tool",
   "language": "python",
   "name": "graph-tool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
